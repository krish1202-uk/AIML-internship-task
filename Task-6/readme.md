# ğŸŒ¿ K-Nearest Neighbors (KNN) Classification on Iris Dataset ğŸŒŸ

## ğŸ“Œ Objective
This project implements the **K-Nearest Neighbors (KNN) algorithm** to classify species in the **Iris dataset**, exploring the impact of different values of **K** and evaluating model performance. ğŸŒ¸  

## ğŸ› ï¸ Tools & Libraries  
ğŸ”¹ **Scikit-learn** â€“ Machine Learning Toolkit ğŸ¤–  
ğŸ”¹ **Pandas & NumPy** â€“ Data Handling & Processing ğŸ“Š  
ğŸ”¹ **Matplotlib & Seaborn** â€“ Visualization Tools ğŸ¨  

## ğŸš€ Workflow & Steps  
### 1ï¸âƒ£ **Data Preparation**  
ğŸ“¥ Load `Iris.csv` dataset.  
ğŸ“Š Remove unnecessary columns (`Id`).  
ğŸ”„ Convert categorical labels (`Species`) into numerical format.  

### 2ï¸âƒ£ **Feature Scaling**  
ğŸ¯ Normalize feature values for better KNN accuracy using **StandardScaler**.  

### 3ï¸âƒ£ **Train KNN Classifier**  
âš™ Train **KNeighborsClassifier** with different values of `K` (`3, 5, 7`).  
ğŸ“Œ Evaluate accuracy for each `K` and select the optimal value.  

### 4ï¸âƒ£ **Model Evaluation**  
âœ” Measure classification **accuracy**.  
ğŸ” **Confusion Matrix** visualization using **Seaborn heatmap**.  

## ğŸ“ Evaluation Metrics  
ğŸ”¹ **Accuracy Score** â€“ Measures correctness âœ…  
ğŸ”¹ **Confusion Matrix** â€“ Analyzes classification performance ğŸ“ˆ  

## ğŸ¯ Key Findings  
âœ” **Feature scaling improves KNN performance** by normalizing input values.  
âœ” **Optimal K selection** ensures better classification accuracy ğŸ¯.  
âœ” **Confusion Matrix** helps analyze misclassifications effectively.  
