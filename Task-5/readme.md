# ğŸŒ³ Decision Trees & ğŸŒ² Random Forests for Heart Disease Prediction

## ğŸ“Œ Objective
In this project, we use **tree-based machine learning models** to predict heart disease risk, comparing the effectiveness of **Decision Trees** and **Random Forests**. ğŸ¥ğŸ’™  

## ğŸ”§ Tools & Libraries  
âœ” **Scikit-learn** â€“ Machine Learning Toolkit ğŸ§   
âœ” **Matplotlib** â€“ Data Visualization ğŸ“Š  
âœ” **Graphviz** â€“ Tree Structure Rendering ğŸŒ  
âœ” **Pandas & NumPy** â€“ Data Handling & Processing ğŸ“‘  

## ğŸš€ Workflow & Steps  
### 1ï¸âƒ£ **Data Preparation**  
ğŸ“‚ Load `heart.csv` dataset.  
ğŸ” Split data into training (80%) and testing (20%) sets.  
âš™ Define feature columns & target labels.  


2ï¸âƒ£ **Decision Tree Model**  
ğŸŒ³ Train `DecisionTreeClassifier` (max_depth=4) ğŸ—  
ğŸ“Š Visualize tree structure to analyze decision logic.  
âœ… Evaluate accuracy using test data.  

### 3ï¸âƒ£ **Overfitting Analysis & Depth Control**  
ğŸ” Limit tree depth for **better generalization** ğŸ“ˆ  
âš– Examine accuracy changes across depths.  

### 4ï¸âƒ£ **Random Forest Model**  
ğŸ”¥ Train `RandomForestClassifier` (100 trees).  
âš¡ Compare accuracy with Decision Tree.  
ğŸ¯ Perform **cross-validation** for robustness.  

### 5ï¸âƒ£ **Feature Importance Analysis**  
ğŸ“Š Identify most influential factors in predictions.  
ğŸ¨ Visualize feature importance rankings.  

## ğŸ“ Evaluation Metrics  
ğŸ”¹ **Accuracy Score** â€“ Measures correctness âœ…  
ğŸ”¹ **Cross-validation** â€“ Ensures reliability ğŸ”„  

## ğŸ¯ Key Findings  
âœ” **Random Forests outperform Decision Trees** due to ensemble learning! ğŸ†  
âœ” Limiting Decision Tree depth **reduces overfitting** âœ…  
âœ” **Feature Importance Analysis** helps understand critical predictors.  

## ğŸ­ Conclusion  
ğŸŒŸ Decision Trees offer **interpretability**, but Random Forests ensure **better accuracy** through ensemble power.  
ğŸ”® Future improvements: **hyperparameter tuning**, **ensemble stacking**, and **deep learning integration**! ğŸš€  


ğŸ’¡ **Pro Tip:** Always test different hyperparameters to optimize tree-based models for the best results! ğŸ”¥  
